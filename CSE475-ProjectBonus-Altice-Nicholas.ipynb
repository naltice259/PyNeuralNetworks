{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LE0FAC9Bqdx"
      },
      "source": [
        "# CSE475 Project Bonus, Due: Monday, 05/02/2022"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnxkmzt2Bqd3"
      },
      "source": [
        "## Instruction\n",
        "\n",
        "1. Please submit your Jupyter Notebook file (the. ipynb file) containing your code and the outputs produced by your code (note that .ipynb file can contain both the code and the outputs) to Canvas. Please name your file CSE475-ProjectBonus-LastName-FirstName.ipynb.\n",
        "\n",
        "2. If you have any questions on the homework problems, you should post your question on the Canvas discussion board (under Project Q&A), instead of sending emails to the instructor or TA. We will answer your questions there. In this way, we can avoid repeated questions, and help the entire class stay on the same page whenever any clarification/correction is made."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49NC9QNHBqd4"
      },
      "source": [
        "## Building a Convolutional Neural Network to classify images in the CIFAR-10 Dataset\n",
        "\n",
        "We will work with the CIFAR-10 Dataset.  This is a well-known dataset for image classification, which consists of 60000 32x32 color images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
        "\n",
        "The 10 classes are:\n",
        "\n",
        "<ol start=\"0\">\n",
        "<li> airplane\n",
        "<li>  automobile\n",
        "<li> bird\n",
        "<li>  cat\n",
        "<li> deer\n",
        "<li> dog\n",
        "<li>  frog\n",
        "<li>  horse\n",
        "<li>  ship\n",
        "<li>  truck\n",
        "</ol>\n",
        "\n",
        "For details about CIFAR-10 see:\n",
        "https://www.cs.toronto.edu/~kriz/cifar.html\n",
        "\n",
        "For a compilation of published performance results on CIFAR 10, see:\n",
        "http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html\n",
        "\n",
        "---\n",
        "\n",
        "### Building CNN\n",
        "\n",
        "In this project we will build and train our convolutional neural network. In the first part, we walk through different layers and how they are configured. In the second part, you will build your own model, train it, and compare the performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "scrolled": true,
        "id": "U5mOX5RBBqd6"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "from tensorflow import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import optimizers\n",
        "from keras.utils import np_utils\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UMv5deABqd7",
        "outputId": "6b37d9b1-ada8-467c-8e95-1e9e059a806e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ],
      "source": [
        "# The data, shuffled and split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eN_4NRjkBqd8",
        "outputId": "8435333c-babd-49d3-d78f-0d7bfa727934"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "## Each image is a 32 x 32 x 3 numpy array\n",
        "x_train[444].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "7TPQGlDsBqd8",
        "outputId": "1f589c8f-1724-4104-d69f-3aa7bc1a65db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[9]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "## Let's look at one of the images\n",
        "\n",
        "print(y_train[444])\n",
        "plt.imshow(x_train[444]);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "jnF2G7jgBqd9"
      },
      "outputs": [],
      "source": [
        "# convert class labels to one-hot vectors\n",
        "num_classes = 10\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnIeYlhWBqd-",
        "outputId": "192bb0b3-5aa2-4e47-f70a-0dd5b8b95f70"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "# see some one-hot vector\n",
        "y_train[444]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "nF5a99y2Bqd_"
      },
      "outputs": [],
      "source": [
        "# As before, let's make everything float and scale\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTHY0MiQBqd_"
      },
      "source": [
        "## First CNN\n",
        "Below we will build our first CNN.  For demonstration purpose (so that it will br trained quickly) it is not very deep and has relatively few parameters.  We use strides of 2 in the first two convolutional layers which quickly reduces the dimensions of the output. After a MaxPooling layer, we flatten, and then have a single fully connected layer before the final classification layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DN_oDfBaBqeA",
        "outputId": "7be65694-9e58-4ebc-c059-9520cf3fdf1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 16, 16, 32)        2432      \n",
            "                                                                 \n",
            " activation_12 (Activation)  (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 6, 6, 32)          25632     \n",
            "                                                                 \n",
            " activation_13 (Activation)  (None, 6, 6, 32)          0         \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 3, 3, 32)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 3, 3, 32)          0         \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 288)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 512)               147968    \n",
            "                                                                 \n",
            " activation_14 (Activation)  (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            " activation_15 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 181,162\n",
            "Trainable params: 181,162\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Let's build a CNN using Keras' Sequential capabilities\n",
        "\n",
        "model_1 = Sequential()\n",
        "\n",
        "## 5x5 convolution with 2x2 stride and 32 filters\n",
        "model_1.add(Conv2D(32, (5, 5), strides = (2,2), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model_1.add(Activation('relu'))\n",
        "\n",
        "## Another 5x5 convolution with 2x2 stride and 32 filters\n",
        "model_1.add(Conv2D(32, (5, 5), strides = (2,2)))\n",
        "model_1.add(Activation('relu'))\n",
        "\n",
        "## 2x2 max pooling reduces to 3 x 3 x 32\n",
        "model_1.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_1.add(Dropout(0.25))\n",
        "\n",
        "## Flatten turns 3x3x32 into 288x1\n",
        "model_1.add(Flatten())\n",
        "model_1.add(Dense(512))\n",
        "model_1.add(Activation('relu'))\n",
        "model_1.add(Dropout(0.5))\n",
        "model_1.add(Dense(num_classes))\n",
        "model_1.add(Activation('softmax'))\n",
        "\n",
        "model_1.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrbt9Cn1BqeA"
      },
      "source": [
        "We still have 181K parameters, even though this is a \"small\" model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYhjoLOcBqeB",
        "outputId": "2d528115-a698-4102-d78c-5bee6897f589"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "391/391 [==============================] - 28s 70ms/step - loss: 1.8590 - accuracy: 0.3229 - val_loss: 1.5568 - val_accuracy: 0.4382\n",
            "Epoch 2/15\n",
            "391/391 [==============================] - 25s 64ms/step - loss: 1.5921 - accuracy: 0.4258 - val_loss: 1.4431 - val_accuracy: 0.4856\n",
            "Epoch 3/15\n",
            "391/391 [==============================] - 26s 67ms/step - loss: 1.4897 - accuracy: 0.4653 - val_loss: 1.3537 - val_accuracy: 0.5158\n",
            "Epoch 4/15\n",
            "391/391 [==============================] - 27s 68ms/step - loss: 1.4159 - accuracy: 0.4891 - val_loss: 1.3207 - val_accuracy: 0.5281\n",
            "Epoch 5/15\n",
            "391/391 [==============================] - 25s 65ms/step - loss: 1.3652 - accuracy: 0.5111 - val_loss: 1.2372 - val_accuracy: 0.5594\n",
            "Epoch 6/15\n",
            "391/391 [==============================] - 25s 65ms/step - loss: 1.3185 - accuracy: 0.5272 - val_loss: 1.2297 - val_accuracy: 0.5621\n",
            "Epoch 7/15\n",
            "391/391 [==============================] - 26s 68ms/step - loss: 1.2789 - accuracy: 0.5426 - val_loss: 1.1883 - val_accuracy: 0.5800\n",
            "Epoch 8/15\n",
            "391/391 [==============================] - 25s 65ms/step - loss: 1.2421 - accuracy: 0.5579 - val_loss: 1.2648 - val_accuracy: 0.5662\n",
            "Epoch 9/15\n",
            "391/391 [==============================] - 25s 64ms/step - loss: 1.2105 - accuracy: 0.5686 - val_loss: 1.2024 - val_accuracy: 0.5643\n",
            "Epoch 10/15\n",
            "391/391 [==============================] - 25s 64ms/step - loss: 1.1829 - accuracy: 0.5778 - val_loss: 1.1048 - val_accuracy: 0.6114\n",
            "Epoch 11/15\n",
            "391/391 [==============================] - 25s 65ms/step - loss: 1.1545 - accuracy: 0.5896 - val_loss: 1.0843 - val_accuracy: 0.6141\n",
            "Epoch 12/15\n",
            "391/391 [==============================] - 25s 65ms/step - loss: 1.1359 - accuracy: 0.5956 - val_loss: 1.0640 - val_accuracy: 0.6269\n",
            "Epoch 13/15\n",
            "391/391 [==============================] - 25s 65ms/step - loss: 1.1091 - accuracy: 0.6041 - val_loss: 1.1080 - val_accuracy: 0.6100\n",
            "Epoch 14/15\n",
            "391/391 [==============================] - 25s 64ms/step - loss: 1.0922 - accuracy: 0.6119 - val_loss: 1.0207 - val_accuracy: 0.6375\n",
            "Epoch 15/15\n",
            "391/391 [==============================] - 25s 64ms/step - loss: 1.0787 - accuracy: 0.6167 - val_loss: 1.0169 - val_accuracy: 0.6421\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f134da87c50>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "batch_size = 128\n",
        "\n",
        "# initiate RMSprop optimizer\n",
        "opt = keras.optimizers.RMSprop(lr=0.0005, decay=1e-6)\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model_1.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_1.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=15,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAu2V2mXBqeB",
        "outputId": "6c46633d-9ca5-400f-e202-871c3f70b6d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 1.01691734790802\n",
            "Test accuracy: 0.6420999765396118\n"
          ]
        }
      ],
      "source": [
        "score = model_1.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "zQpavfSkBqeB"
      },
      "source": [
        "## Your task (25pts)\n",
        "\n",
        "Our previous model (model_1) had the structure:\n",
        "\n",
        "Conv -> Conv -> MaxPool -> (Flatten) -> Dense -> Final Classification (with activation functions and dropouts)\n",
        "\n",
        "Please built a different model (named model_2) by trying different structures and different hyperparameters, such as number of neurons, layers, stride, padding, dropout rate, kernel size, learning rate, number of epochs, etc. You can choose to add data augmentation, batch normalization and/or something new.<br>\n",
        "\n",
        "For example: <br>\n",
        "A deeper model: Conv -> Conv -> MaxPool -> Conv -> Conv -> MaxPool -> (Flatten) -> Dense -> Final Classification\n",
        "<br>\n",
        "\n",
        "Report the best test accuracy achieved. You will be graded on the highest test accuracy achieved:<br>\n",
        "Test accuracy < Base model (model_1) : 0 - 5pts (Depending on the changes made in model_2)<br>\n",
        "Base model (model_1) < Test accuracy < 70%: 5 - 10pts (Depending on the changes made in model_2)<br>\n",
        "70% < Test accuracy < 75%: 15pts<br>\n",
        "75% < Test accuracy: 25pts <br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "9uLPRzkjBqeC"
      },
      "outputs": [],
      "source": [
        "# Let's build a CNN using Keras' Sequential capabilities\n",
        "model_2 = Sequential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aQcsJqiBqeC",
        "outputId": "bc663932-5c14-4b64-ea8c-821487e270aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_11 (Conv2D)          (None, 28, 28, 32)        2432      \n",
            "                                                                 \n",
            " activation_16 (Activation)  (None, 28, 28, 32)        0         \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 24, 24, 32)        25632     \n",
            "                                                                 \n",
            " activation_17 (Activation)  (None, 24, 24, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 12, 12, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 12, 12, 32)        0         \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 4608)              0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 512)               2359808   \n",
            "                                                                 \n",
            " activation_18 (Activation)  (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            " activation_19 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,393,002\n",
            "Trainable params: 2,393,002\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#write your code here\n",
        "model_2.add(Conv2D(32, (5, 5), strides = (1,1), padding='valid', input_shape=x_train.shape[1:]))\n",
        "model_2.add(Activation('relu'))\n",
        "model_2.add(Conv2D(32, (5, 5), strides = (1,1)))\n",
        "model_2.add(Activation('relu'))\n",
        "model_2.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
        "model_2.add(Dropout(0.25))\n",
        "model_2.add(Flatten())\n",
        "model_2.add(Dense(512))\n",
        "model_2.add(Activation('relu'))\n",
        "model_2.add(Dropout(0.5))\n",
        "model_2.add(Dense(num_classes))\n",
        "model_2.add(Activation('softmax'))\n",
        "\n",
        "model_2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "\n",
        "# initiate RMSprop optimizer\n",
        "opt = keras.optimizers.RMSprop(lr=0.0005, decay=1e-6)\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model_2.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_2.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=30,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzUAH5838Wqu",
        "outputId": "25f488d2-28e4-4d49-d884-d435638a6427"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "391/391 [==============================] - 211s 537ms/step - loss: 0.5641 - accuracy: 0.8133 - val_loss: 0.8924 - val_accuracy: 0.7308\n",
            "Epoch 2/30\n",
            "391/391 [==============================] - 208s 533ms/step - loss: 0.5557 - accuracy: 0.8168 - val_loss: 0.9080 - val_accuracy: 0.7280\n",
            "Epoch 3/30\n",
            "391/391 [==============================] - 208s 532ms/step - loss: 0.5442 - accuracy: 0.8214 - val_loss: 0.9048 - val_accuracy: 0.7233\n",
            "Epoch 4/30\n",
            "391/391 [==============================] - 208s 531ms/step - loss: 0.5401 - accuracy: 0.8220 - val_loss: 0.9169 - val_accuracy: 0.7309\n",
            "Epoch 5/30\n",
            "391/391 [==============================] - 207s 530ms/step - loss: 0.5411 - accuracy: 0.8213 - val_loss: 1.0122 - val_accuracy: 0.6941\n",
            "Epoch 6/30\n",
            "391/391 [==============================] - 208s 532ms/step - loss: 0.5338 - accuracy: 0.8234 - val_loss: 0.9826 - val_accuracy: 0.7254\n",
            "Epoch 7/30\n",
            "391/391 [==============================] - 207s 530ms/step - loss: 0.5311 - accuracy: 0.8277 - val_loss: 1.0402 - val_accuracy: 0.7180\n",
            "Epoch 8/30\n",
            "391/391 [==============================] - 207s 531ms/step - loss: 0.5330 - accuracy: 0.8246 - val_loss: 0.8417 - val_accuracy: 0.7296\n",
            "Epoch 9/30\n",
            "391/391 [==============================] - 207s 530ms/step - loss: 0.5307 - accuracy: 0.8271 - val_loss: 0.9193 - val_accuracy: 0.7023\n",
            "Epoch 10/30\n",
            "391/391 [==============================] - 207s 530ms/step - loss: 0.5374 - accuracy: 0.8257 - val_loss: 0.9665 - val_accuracy: 0.7194\n",
            "Epoch 11/30\n",
            "391/391 [==============================] - 207s 530ms/step - loss: 0.5363 - accuracy: 0.8266 - val_loss: 0.9208 - val_accuracy: 0.7249\n",
            "Epoch 12/30\n",
            "391/391 [==============================] - 207s 531ms/step - loss: 0.5275 - accuracy: 0.8291 - val_loss: 0.8901 - val_accuracy: 0.7132\n",
            "Epoch 13/30\n",
            "391/391 [==============================] - 208s 531ms/step - loss: 0.5400 - accuracy: 0.8249 - val_loss: 0.9556 - val_accuracy: 0.7321\n",
            "Epoch 14/30\n",
            "391/391 [==============================] - 208s 533ms/step - loss: 0.5408 - accuracy: 0.8246 - val_loss: 1.0307 - val_accuracy: 0.7278\n",
            "Epoch 15/30\n",
            "391/391 [==============================] - 207s 531ms/step - loss: 0.5421 - accuracy: 0.8240 - val_loss: 0.9217 - val_accuracy: 0.7024\n",
            "Epoch 16/30\n",
            "391/391 [==============================] - 208s 531ms/step - loss: 0.5447 - accuracy: 0.8240 - val_loss: 1.2029 - val_accuracy: 0.7253\n",
            "Epoch 17/30\n",
            "391/391 [==============================] - 207s 531ms/step - loss: 0.5447 - accuracy: 0.8253 - val_loss: 0.8719 - val_accuracy: 0.7173\n",
            "Epoch 18/30\n",
            "391/391 [==============================] - 207s 531ms/step - loss: 0.5391 - accuracy: 0.8272 - val_loss: 0.9082 - val_accuracy: 0.7049\n",
            "Epoch 19/30\n",
            "391/391 [==============================] - 208s 531ms/step - loss: 0.5481 - accuracy: 0.8239 - val_loss: 0.9363 - val_accuracy: 0.7298\n",
            "Epoch 20/30\n",
            "391/391 [==============================] - 207s 531ms/step - loss: 0.5526 - accuracy: 0.8231 - val_loss: 0.8686 - val_accuracy: 0.7292\n",
            "Epoch 21/30\n",
            "391/391 [==============================] - 207s 531ms/step - loss: 0.5383 - accuracy: 0.8245 - val_loss: 0.9565 - val_accuracy: 0.6844\n",
            "Epoch 22/30\n",
            "391/391 [==============================] - 207s 529ms/step - loss: 0.5564 - accuracy: 0.8242 - val_loss: 1.1079 - val_accuracy: 0.7280\n",
            "Epoch 23/30\n",
            "391/391 [==============================] - 208s 533ms/step - loss: 0.5528 - accuracy: 0.8220 - val_loss: 1.2444 - val_accuracy: 0.7026\n",
            "Epoch 24/30\n",
            "391/391 [==============================] - 215s 549ms/step - loss: 0.5600 - accuracy: 0.8195 - val_loss: 1.1600 - val_accuracy: 0.7157\n",
            "Epoch 25/30\n",
            "391/391 [==============================] - 215s 551ms/step - loss: 0.5590 - accuracy: 0.8222 - val_loss: 1.0213 - val_accuracy: 0.7286\n",
            "Epoch 26/30\n",
            "391/391 [==============================] - 223s 570ms/step - loss: 0.5525 - accuracy: 0.8236 - val_loss: 0.9268 - val_accuracy: 0.7108\n",
            "Epoch 27/30\n",
            "391/391 [==============================] - 222s 567ms/step - loss: 0.5611 - accuracy: 0.8201 - val_loss: 0.9158 - val_accuracy: 0.7342\n",
            "Epoch 28/30\n",
            "391/391 [==============================] - 222s 568ms/step - loss: 0.5612 - accuracy: 0.8206 - val_loss: 0.9204 - val_accuracy: 0.7212\n",
            "Epoch 29/30\n",
            "391/391 [==============================] - 222s 569ms/step - loss: 0.5641 - accuracy: 0.8205 - val_loss: 0.9163 - val_accuracy: 0.7079\n",
            "Epoch 30/30\n",
            "391/391 [==============================] - 222s 569ms/step - loss: 0.5714 - accuracy: 0.8192 - val_loss: 0.9271 - val_accuracy: 0.7204\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f134d727c50>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJBdeWJbBqeC",
        "outputId": "eacc7844-43be-47ae-d9c5-16986b3ddd14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.9271363019943237\n",
            "Test accuracy: 0.7203999757766724\n"
          ]
        }
      ],
      "source": [
        "# Test the model on test data\n",
        "score = model_2.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "Project_Bonus.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}